<HTML><HEAD><TITLE>[Chapter 12] 12.3 Reading Debugging Output</TITLE><METANAME="DC.title"CONTENT="DNS &amp; BIND"><METANAME="DC.creator"CONTENT="Cricket Liu &amp; Paul Albitz"><METANAME="DC.publisher"CONTENT="O'Reilly &amp; Associates, Inc."><METANAME="DC.date"CONTENT="1999-01-06T18:38:21Z"><METANAME="DC.type"CONTENT="Text.Monograph"><METANAME="DC.format"CONTENT="text/html"SCHEME="MIME"><METANAME="DC.source"CONTENT="1-56592-512-2"SCHEME="ISBN"><METANAME="DC.language"CONTENT="en-US"><METANAME="generator"CONTENT="Jade 1.1/O'Reilly DocBook 3.0 to HTML 4.0"><LINKREV="made"HREF="mailto:online-books@oreilly.com"TITLE="Online Books Comments"><LINKREL="up"HREF="ch12_01.htm"TITLE="12. Reading BIND Debugging Output"><LINKREL="prev"HREF="ch12_02.htm"TITLE="12.2 Turning On Debugging"><LINKREL="next"HREF="ch12_04.htm"TITLE="12.4 The Resolver Search Algorithm and Negative Caching"></HEAD><BODYBGCOLOR="#FFFFFF"TEXT="#000000"><DIVCLASS="htmlnav"><H1><IMGSRC="gifs/smbanner.gif"ALT="DNS &amp; BIND"USEMAP="#srchmap"BORDER="0"></H1><MAPNAME="srchmap"><AREASHAPE="RECT"COORDS="0,0,466,65"HREF="index.htm"ALT="DNS &amp; BIND"><AREASHAPE="RECT"COORDS="467,0,514,18"HREF="../search/dsrch.htm"ALT="Search this book"></MAP><TABLEWIDTH="515"BORDER="0"CELLSPACING="0"CELLPADDING="0"><TR><TDALIGN="LEFT"VALIGN="TOP"WIDTH="172"><ACLASS="SECT1"HREF="ch12_02.htm"TITLE="12.2 Turning On Debugging"><IMGSRC="../gifs/txtpreva.gif"ALT="Previous: 12.2 Turning On Debugging"BORDER="0"></A></TD><TDALIGN="CENTER"VALIGN="TOP"WIDTH="171"><B><FONTFACE="ARIEL,HELVETICA,HELV,SANSERIF"SIZE="-1">Chapter 12<BR>Reading <SPANCLASS="acronym">BIND</SPAN> Debugging Output</FONT></B></TD><TDALIGN="RIGHT"VALIGN="TOP"WIDTH="172"><ACLASS="SECT1"HREF="ch12_04.htm"TITLE="12.4 The Resolver Search Algorithm and Negative Caching"><IMGSRC="../gifs/txtnexta.gif"ALT="Next: 12.4 The Resolver Search Algorithm and Negative Caching"BORDER="0"></A></TD></TR></TABLE>&nbsp;<HRALIGN="LEFT"WIDTH="515"TITLE="footer"></DIV><DIVCLASS="SECT1"><H2CLASS="sect1"><ACLASS="title"NAME="AUTOID-13025">12.3 Reading Debugging Output</A></H2><PCLASS="para"><ACLASS="indexterm"NAME="DNS3-IDX-12-READING-DEBUGGING-OUTPUT"></A><ACLASS="indexterm"NAME="DNS3-IDX-12-DEBUGGING-INTERPRETING-OUTPUT"></A><ACLASS="indexterm"NAME="AUTOID-13034"></A>We'll cover five examples of debugging output. The first example showsthe name server starting up. The next two examples show successfulname lookups. The fourth example shows a secondary name server keepingits zone up to date. In the last example, we switch from showing youname server behavior to showing you resolver behavior: the resolversearch algorithm. After each trace, except the last one, we killed thename server and started it again so that each trace started with afresh, nearly empty cache.</P><PCLASS="para">You might wonder why we've chosen to show normal name serverbehavior for all our examples; after all, this chapter is aboutdebugging. We are showing you normal behavior because you have to knowwhat normal operation <EMCLASS="emphasis">is</EM> before you track downabnormal operation. Another reason is to help you<EMCLASS="emphasis">understand</EM> the concepts (retransmissions, roundtrip times, etc.) we have described in earlier chapters.</P><DIVCLASS="sect2"><H3CLASS="sect2"><ACLASS="title"NAME="AUTOID-13040">12.3.1 Name Server Startup (Debug Level 1)</A></H3><PCLASS="para"><ACLASS="indexterm"NAME="DNS3-IDX-12-NAME-SERVERS-INITIALIZATION-OF-DEBUGGING-EXAMPLE"></A><ACLASS="indexterm"NAME="DNS3-IDX-12-INITIALIZING-NAME-SERVER-DEBUGGING-EXAMPLE"></A>We'll start the debugging examples by watching the name serverinitialize. We used <ICLASS="option">-d 1</I> on the command line, andthis is the <KBDCLASS="command">named.run</KBD> output that resulted:</P><BLOCKQUOTECLASS="screen"><PRECLASS="screen">1)  Debug level 12)  Version = named 8.1.1 Sat Jul 19 08:06:36 EDT 19973)      pma@terminator:/home/pma/named4)  conffile = named.conf5)  starting.  named 8.1.1 Sat Jul 19 08:06:36 EDT 19976)      pma@terminator:/home/pma/named7)  ns_init(named.conf)8)  update_zone_info('0.0.127.IN-ADDR.ARPA', 1)9)  source = db.127.0.010) purge_zone(0.0.127.IN-ADDR.ARPA,1)11) reloading zone12) db_load(db.127.0.0, 0.0.127.IN-ADDR.ARPA, 1, Nil)13) np_parent(0x0) couldn't find root entry14) master zone &quot;0.0.127.IN-ADDR.ARPA&quot; (IN) loaded (serial 1)15) zone[1] type 1: '0.0.127.IN-ADDR.ARPA' z_time 0, z_refresh 016) update_zone_info('.', 3)17) source = db.cache18) reloading zone19) db_load(db.cache, , 0, Nil)20) cache zone &quot;&quot; (IN) loaded (serial 0)21) zone[0] type 3: '.' z_time 0, z_refresh 022) getnetconf(generation 887560796)23) getnetconf: considering lo [127.0.0.1]24) ifp-&gt;addr [127.0.0.1].53 d_dfd 2025) evSelectFD(ctx 0x808f0e0, fd 20, mask 0x1, func 0x8056bf0,    uap 0x80ac350)26) evSelectFD(ctx 0x808f0e0, fd 21, mask 0x1, func 0x806fb08,    uap 0x80ac398)27) listening [127.0.0.1].53 (lo)28) getnetconf: considering eth0 [192.249.249.3]29) ifp-&gt;addr [192.249.249.3].53 d_dfd 2230) evSelectFD(ctx 0x808f0e0, fd 22, mask 0x1, func 0x8056bf0,    uap 0x80ac408)31) evSelectFD(ctx 0x808f0e0, fd 23, mask 0x1, func 0x806fb08,    uap 0x80ac450)32) listening [192.249.249.3].53 (eth0)33) fwd ds 5 addr [0.0.0.0].114234) Forwarding source address is [0.0.0.0].114235) evSelectFD(ctx 0x808f0e0, fd 5, mask 0x1, func 0x8056bf0, uap 0)36) exit ns_init()37) Ready to answer queries.38) prime_cache: priming = 039) evSetTimer(ctx 0x808f0e0, func 0x8054cf4,    uap 0, due 887560800.000000000, inter 0.000000000)40) sysquery: send -&gt; [192.5.5.241].53 dfd=5 nsid=41705 id=0 41)    retry=88756080041) evSetTimer(ctx 0x808f0e0, func 0x804ee88,    uap 0x80a4a20, due 887560803.377717000, inter 0.000000000)42) datagram from [192.5.5.241].53, fd 5, len 43643) 13 root servers</PRE></BLOCKQUOTE><PCLASS="para">We added the line numbers to the debugging output; you won't seethem in yours. Lines 2 through 6 give the version of<SPANCLASS="acronym">BIND</SPAN> you are running and the name of theconfiguration file. Version 8.1.1 was released by<SPANCLASS="acronym">ISC</SPAN> (Internet Software Consortium) in 1997. We usedthe configuration file in the current directory,<ICLASS="filename">./named.conf</I>, for this run.</P><PCLASS="para">Lines 7 through 21 show <SPANCLASS="acronym">BIND</SPAN> reading theconfiguration file and the db files. This name server is acaching-only name server&nbsp;- the only files read are<ICLASS="filename">db.127.0.0</I> (lines 8 through 15) and<ICLASS="filename">db.cache</I> (lines 16-21).  Line 8 lists thezone being updated (<ICLASS="systemitem.sitename">0.0.127.<SPANCLASS="acronym">IN-ADDR</SPAN>.<SPANCLASS="acronym">ARPA</SPAN></I>)and line 9 shows the file containing the zone data(<ICLASS="filename">db.127.0.0</I>).  Line 10 indicates that any olddata for the zone is purged before new data is added.  Line 11 saysthe zone is being reloaded, even though the zone is actually beingloaded for the first time.  The zone data is loaded during lines 12through 14.  Ignore the useless error message on line 13.  On lines 15and 21, <KBDCLASS="command">z_time</KBD> is the time to check when this zoneis up to date; <KBDCLASS="command">z_refresh</KBD> is the zone refreshtime. These values only matter when the server is a secondary serverfor the zone.</P><PCLASS="para">Lines 22 through 35 show the initialization of<ACLASS="indexterm"NAME="AUTOID-13067"></A>file descriptors. (In this case, they're really<ACLASS="indexterm"NAME="AUTOID-13069"></A>socket descriptors.)  File descriptors 20 and 21 (lines 24-26)are bound to 127.0.0.1, the loopback address. Descriptor 20 is adatagram socket and descriptor 21 is a stream socket.  Filedescriptors 22 and 23 (lines 29-31) are bound to the192.249.249.3 interface. Each interface address was considered andused&nbsp;- they would not be used if the interface had not beeninitialized, or if the address were already in the list. Filedescriptor 5 (lines 33-35) is bound to 0.0.0.0, the wildcardaddress. Most network daemons use only one socket bound to thewildcard address, not sockets bound to individual interfaces.  Thewildcard address picks up packets sent to any interface on thehost. Let's digress for a moment to explain why<KBDCLASS="command">named</KBD> uses both a socket bound to the wildcardaddress and sockets bound to specific interfaces.</P><PCLASS="para">When <KBDCLASS="command">named</KBD> receives a request from anapplication or from another name server, it will receive the requeston one of the sockets bound to a specific interface. If<KBDCLASS="command">named</KBD> did not have sockets bound to specificinterfaces, it would receive the requests on the socket bound to thewildcard address. When <KBDCLASS="command">named</KBD> sends back a response,it uses the same socket descriptor that the request came in on. Whydoes <KBDCLASS="command">named</KBD> do this? When responses are sent out viathe socket bound to the wildcard address, the kernel fills in thesender's address with the address of the interface the response wasactually sent out on. This address may or may not be the same addressthat the request was sent to. When responses are sent out via thesocket bound to a specific address, the kernel fills in the sender'saddress with that specific address&nbsp;- the same address the requestwas sent to. If the name server gets a response from an<SPANCLASS="acronym">IP</SPAN> address it didn't know about, the response istagged a <SPANCLASS="quote">"martian"</SPAN> anddiscarded. <KBDCLASS="command">named</KBD> tries to avoid martian responsesby sending its responses on descriptors bound to specific interfaces,so the sender's address is the same address the request was sentto. However, when <KBDCLASS="command">named</KBD> sends out<EMCLASS="emphasis">queries</EM>, it uses the wildcard descriptor, sincethere is no need to force a specific <SPANCLASS="acronym">IP</SPAN>address.</P><PCLASS="para">Lines 38 through 43 show the name server sending out a systemquery to find out which name servers are currently serving the rootdomain. This is known as <SPANCLASS="quote">"priming the cache."</SPAN> The firstserver queried sent a response that included 13 nameservers.</P><PCLASS="para">The name server is now initialized, and it is ready to answerqueries.<ACLASS="indexterm"NAME="AUTOID-13086"></A><ACLASS="indexterm"NAME="AUTOID-13087"></A></P></DIV><DIVCLASS="sect2"><H3CLASS="sect2"><ACLASS="title"NAME="AUTOID-13088">12.3.2 A Successful Lookup (Debug Level 1)</A></H3><PCLASS="para"><ACLASS="indexterm"NAME="DNS3-IDX-12-QUERIES-SUCCESSFUL-DEBUGGING-EXAMPLE"></A><ACLASS="indexterm"NAME="DNS3-IDX-12-SUCCESSFUL-LOOKUPS-DEBUGGING-EXAMPLE"></A>Suppose you want to watch the name server look up a name.  Your nameserver wasn't started with debugging. Send a <SPANCLASS="acronym">USR</SPAN>1signal to turn on debugging, look up the name, then send a<SPANCLASS="acronym">USR</SPAN>2 signal to turn off debugging, likethis:</P><BLOCKQUOTECLASS="screen"><PRECLASS="screen"># <CODECLASS="userinput"><B>kill -USR1 `cat /etc/named.pid`</B></CODE># <CODECLASS="userinput"><B>/etc/ping galt.cs.purdue.edu.</B></CODE># <CODECLASS="userinput"><B>kill -USR2 `cat /etc/named.pid`</B></CODE></PRE></BLOCKQUOTE><PCLASS="para">We did this; here's the resulting <ICLASS="filename">named.run</I>file:</P><BLOCKQUOTECLASS="screen"><PRECLASS="screen">datagram from [192.249.249.3].1162, fd 20, len 36req: nlookup(galt.cs.purdue.edu) id 29574 type=1 class=1req: missed 'galt.cs.purdue.edu' as '' (cname=0)forw: forw -&gt; [198.41.0.10].53 ds=4 nsid=40070 id=29574 2ms retry 4secdatagram from [198.41.0.10].53, fd 4, len 343;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 40070;; flags: qr; QUERY: 1, ANSWER: 0, AUTHORITY: 9, ADDITIONAL: 9;;              galt.cs.purdue.edu, type = A, class = INEDU.                        6D IN NS    A.ROOT-SERVERS.NET.EDU.                        6D IN NS    H.ROOT-SERVERS.NET.EDU.                        6D IN NS    B.ROOT-SERVERS.NET.EDU.                        6D IN NS    C.ROOT-SERVERS.NET.EDU.                        6D IN NS    D.ROOT-SERVERS.NET.EDU.                        6D IN NS    E.ROOT-SERVERS.NET.EDU.                        6D IN NS    I.ROOT-SERVERS.NET.EDU.                        6D IN NS    F.ROOT-SERVERS.NET.EDU.                        6D IN NS    G.ROOT-SERVERS.NET.A.ROOT-SERVERS.NET.             5w6d16h IN A    198.41.0.4H.ROOT-SERVERS.NET.             5w6d16h IN A    128.63.2.53B.ROOT-SERVERS.NET.             5w6d16h IN A    128.9.0.107C.ROOT-SERVERS.NET.             5w6d16h IN A    192.33.4.12D.ROOT-SERVERS.NET.             5w6d16h IN A    128.8.10.90E.ROOT-SERVERS.NET.             5w6d16h IN A    192.203.230.10I.ROOT-SERVERS.NET.             5w6d16h IN A    192.36.148.17F.ROOT-SERVERS.NET.             5w6d16h IN A    192.5.5.241G.ROOT-SERVERS.NET.             5w6d16h IN A    192.112.36.4resp: nlookup(galt.cs.purdue.edu) qtype=1resp: found 'galt.cs.purdue.edu' as 'edu' (cname=0)resp: forw -&gt; [192.36.148.17].53 ds=4 nsid=40071 id=29574 1msdatagram from [192.36.148.17].53, fd 4, len 202;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 40071;; flags: qr rd; QUERY: 1, ANSWER: 0, AUTHORITY: 4, ADDITIONAL: 4;;   galt.cs.purdue.edu, type = A, class = INPURDUE.EDU.                 2D IN NS    NS.PURDUE.EDU.PURDUE.EDU.                 2D IN NS    MOE.RICE.EDU.PURDUE.EDU.                 2D IN NS    PENDRAGON.CS.PURDUE.EDU.PURDUE.EDU.                 2D IN NS    HARBOR.ECN.PURDUE.EDU.NS.PURDUE.EDU.                  2D IN A     128.210.11.5MOE.RICE.EDU.                   2D IN A     128.42.5.4PENDRAGON.CS.PURDUE.EDU.              2D IN A  128.10.2.5HARBOR.ECN.PURDUE.EDU.              2D IN A     128.46.199.76resp: nlookup(galt.cs.purdue.edu) qtype=1resp: found 'galt.cs.purdue.edu' as 'cs.purdue.edu' (cname=0)resp: forw -&gt; [128.46.199.76].53 ds=4 nsid=40072 id=29574 8msdatagram from [128.46.199.76].53, fd 4, len 234send_msg -&gt; [192.249.249.3].1162 (UDP 20) id=29574Debug off</PRE></BLOCKQUOTE><PCLASS="para">First, notice that <SPANCLASS="acronym">IP</SPAN> addresses are logged,not names&nbsp;- odd for a <EMCLASS="emphasis">name</EM> server, don't youthink? It's not that odd, though. If you are trying to debug a problemwith looking up names, you don't want the name server looking upadditional names just to make the debugging output morereadable&nbsp;- the extra queries would interfere with thedebugging. None of the debugging levels translate<SPANCLASS="acronym">IP</SPAN> addresses into names. You'll have to use a tool(like the one we provide later) to convert them for you.</P><PCLASS="para">Let's go through this debugging output line by line. Thisdetailed approach is important if you want to understand what eachline means. If you turn on debugging, you're probably trying to findout why some name can't be looked up, and you're going to have tofigure out what the trace means.</P><BLOCKQUOTECLASS="screen"><PRECLASS="screen">datagram from [192.249.249.3].1162, fd 20, len 36</PRE></BLOCKQUOTE><PCLASS="para">A datagram came from the host with <SPANCLASS="acronym">IP</SPAN> address192.249.249.3 (<ICLASS="systemitem.sitename">terminator</I>). You may see the datagramcome from 127.0.0.1 if the sender is on the same host as the nameserver.  The sending application used port 1162. The name serverreceived the datagram on file descriptor (<ICLASS="parameter">fd</I>) 20. The startupdebugging output, like the one shown earlier, will tell you whichinterface file descriptor 20 is bound to. The length (<ICLASS="parameter">len</I>) of thedatagram was 36 bytes.</P><BLOCKQUOTECLASS="screen"><PRECLASS="screen">req: nlookup(galt.cs.purdue.edu) id 29574 type=1 class=1</PRE></BLOCKQUOTE><PCLASS="para">Since the next debugging line starts with<CODECLASS="literal">req</CODE>, we know that the datagram was a<EMCLASS="emphasis">request</EM>. The name looked up in the request was<ICLASS="systemitem.sitename">galt.cs.purdue.edu</I>. Therequest id is 29574. The <CODECLASS="literal">type=1</CODE> means the requestis for <EMCLASS="emphasis">address</EM> information.  The<CODECLASS="literal">class=1</CODE> means the class was<SPANCLASS="acronym">IN</SPAN>. You will find a complete list of query typesand classes in the header file<ICLASS="filename">/usr/include/arpa/nameser.h</I>.</P><BLOCKQUOTECLASS="screen"><PRECLASS="screen">req: missed 'galt.cs.purdue.edu' as '' (cname=0)</PRE></BLOCKQUOTE><PCLASS="para">The name server looked up the requested name and didn't findit. Then it tried to find a remote name server to ask; none was founduntil the root domain (the empty quotes). The<KBDCLASS="command">cname=0</KBD> means the name server has not encountered a<SPANCLASS="acronym">CNAME</SPAN> record. If it does see a<SPANCLASS="acronym">CNAME</SPAN> record, the canonical name is looked upinstead of the original name, and <KBDCLASS="command">cname</KBD> will benonzero.</P><BLOCKQUOTECLASS="screen"><PRECLASS="screen">forw: forw -&gt; [198.41.0.10].53 ds=4 nsid=40070 id=29574 2ms retry 4sec</PRE></BLOCKQUOTE><PCLASS="para">The query was forwarded to the name server (port53) on host 198.41.0.10 (<ICLASS="systemitem.sitename">j.root-servers.net</I>). The name server usedfile descriptor 4 (which is the wildcard address)to send the query. The name server tagged this query with<SPANCLASS="acronym">ID</SPAN> number 40070 (<KBDCLASS="command">nsid=40070</KBD>) sothat it could match the response to the original question. Theapplication used <SPANCLASS="acronym">ID</SPAN> number 29574(<KBDCLASS="command">id=29574</KBD>), as you saw on the<KBDCLASS="command">nlookup</KBD> line.  The name server will wait4 seconds before trying the next nameserver.</P><BLOCKQUOTECLASS="screen"><PRECLASS="screen">datagram from [198.41.0.10].53, fd 4, len 343</PRE></BLOCKQUOTE><PCLASS="para">The name server on <ICLASS="systemitem.sitename">j.root-servers.net</I> responded.  Since theresponse was a delegation, it is printed in full in the debuglog.</P><BLOCKQUOTECLASS="screen"><PRECLASS="screen">resp: nlookup(galt.cs.purdue.edu) qtype=1</PRE></BLOCKQUOTE><PCLASS="para">After the information is cached in the response packet, the nameis looked up again. As mentioned earlier, <CODECLASS="literal">querytype=1</CODE> means that the name server is looking for<EMCLASS="emphasis">address</EM> information.</P><BLOCKQUOTECLASS="screen"><PRECLASS="screen">resp: found 'galt.cs.purdue.edu' as 'edu' (cname=0)resp: forw -&gt; [192.36.148.17].53 ds=4 nsid=40071 id=29574 1msdatagram from [192.36.148.17].53, fd 4, len 202</PRE></BLOCKQUOTE><PCLASS="para">The root server responded with a delegation to the <ICLASS="systemitem.sitename">edu</I> servers.  The same query is sent to192.36.148.17 (<ICLASS="systemitem.sitename">i.root-servers.net</I>), one of the<ICLASS="systemitem.sitename">edu</I> servers.  <ICLASS="systemitem.sitename">i.root-servers.net</I> responds withinformation about the <ICLASS="systemitem.sitename">purdue.edu</I> servers.</P><BLOCKQUOTECLASS="screen"><PRECLASS="screen">resp: found 'galt.cs.purdue.edu' as 'cs.purdue.edu' (cname=0)</PRE></BLOCKQUOTE><PCLASS="para">This time there is some information at the <ICLASS="systemitem.sitename">cs.purdue.edu</I> level.</P><BLOCKQUOTECLASS="screen"><PRECLASS="screen">resp: forw -&gt; [128.46.199.76].53 ds=4 nsid=40072 id=29574 8ms</PRE></BLOCKQUOTE><PCLASS="para">A query was sent to the name server on 128.46.199.76(<ICLASS="systemitem.sitename">harbor.ecn.purdue.edu</I>).Thistime the name server <SPANCLASS="acronym">ID</SPAN> is 40072.</P><BLOCKQUOTECLASS="screen"><PRECLASS="screen">datagram from [128.46.199.76].53, fd 4, len 234</PRE></BLOCKQUOTE><PCLASS="para">The name server on <ICLASS="systemitem.sitename">harbor.ecn.purdue.edu</I> responded.  We haveto look at what happens next to figure out the contents of thisresponse.</P><BLOCKQUOTECLASS="screen"><PRECLASS="screen">send_msg -&gt; [192.249.249.3].1162 (UDP 20) id=29574</PRE></BLOCKQUOTE><PCLASS="para">The last response must have contained the address requested,since the name server responded to the application (which used port1162, if you look back at the original query). The response was in a<SPANCLASS="acronym">UDP</SPAN> packet (as opposed to a <SPANCLASS="acronym">TCP</SPAN>connection), and it used file descriptor 20.</P><PCLASS="para">This name server was <SPANCLASS="quote">"quiet"</SPAN> when we did thistrace; it wasn't handling other queries at the same time. When you doa trace on an active name server you won't be so lucky. You'll have tosift through the output and patch together those pieces that pertainto the lookup in which you are interested. It's not that hard, though.Start up your favorite editor, search for the<KBDCLASS="command">nlookup</KBD> line with the name you looked up, thentrace the entries with the same <KBDCLASS="command">nsid</KBD>. You'll seehow to follow the <KBDCLASS="command">nsid</KBD> in the next trace.<ACLASS="indexterm"NAME="AUTOID-13173"></A><ACLASS="indexterm"NAME="AUTOID-13174"></A></P></DIV><DIVCLASS="sect2"><H3CLASS="sect2"><ACLASS="title"NAME="AUTOID-13175">12.3.3 A Successful Lookup with Retransmissions(Debug Level 1)</A></H3><PCLASS="para"><ACLASS="indexterm"NAME="DNS3-IDX-12-QUERIES-RETRANSMITTED-DEBUGGING-EXAMPLE"></A><ACLASS="indexterm"NAME="DNS3-IDX-12-RETRANSMITTING-QUERIES-DEBUGGING-EXAMPLE"></A>Not all lookups are as <SPANCLASS="quote">"clean"</SPAN> as the lastone&nbsp;- sometimes the query must be retransmitted. The user doesn'tsee any difference so long as the lookup succeeds, although the queryinvolving retransmissions will take longer. Following is a trace wherethere are retransmissions.  We converted the <SPANCLASS="acronym">IP</SPAN>addresses to names after the trace was done.  Notice how much easierit is to read with names!</P><BLOCKQUOTECLASS="screen"><PRECLASS="screen">1)  Debug turned ON, Level 12)3)  datagram from terminator.movie.edu port 3397, fd 20, len 354)  req: nlookup(ucunix.san.uc.edu) id 1 type=1 class=15)  req: found 'ucunix.san.uc.edu' as 'edu' (cname=0)6)  forw: forw -&gt; i.root-servers.net port 53  ds=4 nsid=2 id=1 0ms    retry 4 sec7)8)  datagram from i.root-servers.net port 53, fd 4, len 240    &lt;delegation lines removed&gt;9)  resp: nlookup(ucunix.san.uc.edu) qtype=110) resp: found 'ucunix.san.uc.edu' as 'san.uc.edu' (cname=0)11) resp: forw -&gt; uceng.uc.edu port 53 ds=4 nsid=3 id=1 0ms12) resend(addr=1 n=0) - &gt; ucbeh.san.uc.edu port 53 ds=4 nsid=3    id=1 0ms13)14) datagram from terminator.movie.edu port 3397, fd 20, len 3515) req: nlookup(ucunix.san.uc.edu) id 1 type=1 class=116) req: found 'ucunix.san.uc.edu' as 'san.uc.edu' (cname=0)17) resend(addr=2 n=0) - &gt; uccba.uc.edu port 53 ds=4 nsid=3 id=1 0ms18) resend(addr=3 n=0) - &gt; mail.cis.ohio-state.edu port 53 ds=4 nsid=3    id=1 0ms19)20) datagram from mail.cis.ohio-state.edu port 53, fd 4, len 5121) send_msg -&gt; terminator.movie.edu (UDP 20 3397) id=1</PRE></BLOCKQUOTE><PCLASS="para">This trace starts out like the last trace (lines 1 through 11):the name server receives a query for <ICLASS="systemitem.sitename">ucunix.san.uc.edu</I>, sends the query to an<ICLASS="systemitem.sitename">edu</I> name server (<ICLASS="systemitem.sitename">i.root-servers.net</I>), receives a responsethat includes a list of name servers for <ICLASS="systemitem.sitename">uc.edu</I>, and sends the query to one of the<ICLASS="systemitem.sitename">uc.edu</I> name servers(<ICLASS="systemitem.sitename">uceng.uc.edu</I>).</P><PCLASS="para">What's new in this trace is the <KBDCLASS="command">resend</KBD> lines(lines 12, 17, and 18). The <KBDCLASS="command">forw</KBD> on line 11 countsas <SPANCLASS="quote">"resend(addr=0 n=0)"</SPAN>&nbsp;- <SPANCLASS="acronym">CS</SPAN>dweebs always start counting with zero.  Since <ICLASS="systemitem.sitename">uceng.uc.edu</I> didn't respond, the nameserver went on to try <ICLASS="systemitem.sitename">ucbeh</I>(line 12), <ICLASS="systemitem.sitename">uccba</I> (line 17),and <ICLASS="systemitem.sitename">mail</I> (line 18). Theoff-site name server on <ICLASS="systemitem.sitename">mail.cis.ohio-state.edu</I> finally responded(line 20).  Notice that you can track all of the retransmissions bysearching for <KBDCLASS="command">nsid=3</KBD>; that's important to knowbecause lots of other queries can be wedged between these.</P><PCLASS="para">Also, notice the second datagram from <ICLASS="systemitem.sitename">terminator</I> (line 14).  It has the sameport, file descriptor, length, <SPANCLASS="acronym">ID</SPAN>, and type as thequery on line 3. The application didn't receive a response in time, soit retransmitted its original query. Since the name server is stillworking on the first query transmitted, this one is a duplicate.  Itdoesn't say so in this output, but the name server detected theduplicate and dropped it. We can tell because there is no<KBDCLASS="command">forw:</KBD> line after the <KBDCLASS="command">req:</KBD> lines,as there was on lines 4 through 6.</P><PCLASS="para">Can you guess what this output might look like if the nameserver were having trouble looking up a name? You'd see a lot ofretransmissions as the name server kept trying to look up the name(which you could track by matching the <KBDCLASS="command">nsid=</KBD>lines).  You'd see the application send a couple more retransmissions,thinking that the name server hadn't received the application's firstquery.  Eventually the name server would give up, usually after theapplication itself gave up.<ACLASS="indexterm"NAME="AUTOID-13211"></A><ACLASS="indexterm"NAME="AUTOID-13212"></A></P></DIV><DIVCLASS="sect2"><H3CLASS="sect2"><ACLASS="title"NAME="AUTOID-13213">12.3.4 A Slave Name Server Checking Its Zone(Debug Level&nbsp;1)</A></H3><PCLASS="para"><ACLASS="indexterm"NAME="DNS3-IDX-12-ZONES-CHECKING-DEBUGGING-EXAMPLE"></A><ACLASS="indexterm"NAME="DNS3-IDX-12-CHECKING-ZONE-DEBUGGING-EXAMPLE"></A><ACLASS="indexterm"NAME="DNS3-IDX-12-SLAVE-SECONDARY-NAME-SERVERS-CHECKING-ZONE-DEBUGGING-EXAMPLE"></A>In addition to tracking down problems with name server lookups, youmay have to track down why a slave server is not loading from itsmaster. Tracking down this problem can often be done by simplycomparing the domain's <SPANCLASS="acronym">SOA</SPAN> serial numbers on thetwo servers, using <KBDCLASS="command">nslookup</KBD> or<KBDCLASS="command">dig</KBD>, as we'll show in <ACLASS="xref"HREF="ch13_01.htm"TITLE="Troubleshooting DNS and BIND">Chapter 13</A>. If your problem is more elusive, you may haveto resort to looking at the debugging information. We'll show you whatthe debugging information should look like if your server is runningnormally.</P><PCLASS="para">This debugging output was generated on a <SPANCLASS="quote">"quiet"</SPAN>name server&nbsp;- one not receiving any queries&nbsp;- to show youexactly which lines pertain to zone maintenance. If you remember, aslave name server uses a child process to transfer the zone datato the local disk before reading it in. While the slave logs itsdebugging information to <ICLASS="filename">named.run</I>, theslave's child process logs its debugging information to<ICLASS="filename">xfer.ddt.PID</I>.  The <ICLASS="filename">PID</I>suffix, by default the process <SPANCLASS="acronym">ID</SPAN> of the childprocess, may be changed to ensure that the filename isunique. Beware&nbsp;- turning on debugging on a slave name serverwill leave <ICLASS="filename">xfer.ddt.PID</I> files lying around, evenif you are only trying to trace a lookup. Our trace is at debugginglevel 1 and we turned on the <SPANCLASS="acronym">BIND</SPAN> 8 logging option<ICLASS="option">print-time</I>. Debug level 3 gives you more information, more than youmay want if a transfer actually occurs. A debugging level 3 trace of azone transfer of several hundred resource records can create an<ICLASS="filename">xfer.ddt.PID</I> file several megabytes large:</P><BLOCKQUOTECLASS="screen"><PRECLASS="screen">21-Feb 00:13:18.026 do_zone_maint for zone movie.edu (class IN)21-Feb 00:13:18.034 zone_maint('movie.edu')21-Feb 00:13:18.035 qserial_query(movie.edu)21-Feb 00:13:18.043 sysquery: send -&gt; [192.249.249.3].53 dfd=5                         nsid=29790 id=0 retry=88804880221-Feb 00:13:18.046 qserial_query(movie.edu) QUEUED21-Feb 00:13:18.052 next maintenance for zone 'movie.edu' in 2782 sec21-Feb 00:13:18.056 datagram from [192.249.249.3].53, fd 5, len 38021-Feb 00:13:18.059 qserial_answer(movie.edu, 26739)21-Feb 00:13:18.060 qserial_answer: zone is out of date21-Feb 00:13:18.061 startxfer() movie.edu21-Feb 00:13:18.063 /usr/etc/named-xfer -z movie.edu -f db.movie                    -s 26738 -C 1 -P 53 -d 1 -l xfer.ddt 192.249.249.321-Feb 00:13:18.131 started xfer child 39021-Feb 00:13:18.132 next maintenance for zone 'movie.edu' in 7200 sec21-Feb 00:14:02.089 endxfer: child 390 zone movie.edu returned                         status=1 termsig=-121-Feb 00:14:02.094 loadxfer() &quot;movie.edu&quot;21-Feb 00:14:02.094 purge_zone(movie.edu,1)21-Feb 00:14:30.049 db_load(db.movie, movie.edu, 2, Nil)21-Feb 00:14:30.058 next maintenance for zone 'movie.edu' in 1846 sec21-Feb 00:17:12.478 slave zone &quot;movie.edu&quot; (IN) loaded (serial 26739)21-Feb 00:17:12.486 no schedule change for zone 'movie.edu'21-Feb 00:42:44.817 Cleaned cache of 0 RRs21-Feb 00:45:16.046 do_zone_maint for zone movie.edu (class IN)21-Feb 00:45:16.054 zone_maint('movie.edu')21-Feb 00:45:16.055 qserial_query(movie.edu)21-Feb 00:45:16.063 sysquery: send -&gt; [192.249.249.3].53 dfd=5                         nsid=29791 id=0 retry=88805066021-Feb 00:45:16.066 qserial_query(movie.edu) QUEUED21-Feb 00:45:16.067 next maintenance for zone 'movie.edu' in 3445 sec21-Feb 00:45:16.074 datagram from [192.249.249.3].53, fd 5, len 38021-Feb 00:45:16.077 qserial_answer(movie.edu, 26739)21-Feb 00:45:16.078 qserial_answer: zone serial is still OK21-Feb 00:45:16.131 next maintenance for zone 'movie.edu' in 2002 sec</PRE></BLOCKQUOTE><PCLASS="para">Unlike the previous traces, each line in this trace has atimestamp.  The timestamp makes clear which debug statements aregrouped together.</P><PCLASS="para">This server is a slave for a single zone, <ICLASS="systemitem.sitename">movie.edu</I>.  The line with time00:13:18.026 shows that it is time to check with the masterserver. The server queries for the zone's <SPANCLASS="acronym">SOA</SPAN>record and compares serial numbers before deciding to load thezone. The lines with times 00:13:18.059 through 00:13:18.131 show youthe zone's serial number (26739), tell you the zone is out of date,and start a child process (pid 390) to transfer the zone.  At time00:13:18.132, a timer is set to expire 7200 seconds later.  This isthe amount of time the server allows for a transfer to complete.  Attime 00:14:02.089, you see the exit status of the child process. Thestatus of 1 indicates that the zone data was successfullytransferred. The old zone data is purged (time 00:14:02.094), and thenew data is loaded.</P><PCLASS="para">The next maintenance (see time 00:14:30.058) is scheduled for1846 seconds later.  For this zone, the refresh interval is 3600, butthe name server chose to check again in 1846 seconds.  Why?  The nameserver is trying to avoid having the refresh periods becomesynchronized.  Instead of using 3600 exactly, it uses a random timebetween half the refresh interval (1800) and the full refresh interval(3600).  At 00:45:16.046, the zone is checked again and this time itis up-to-date.</P><PCLASS="para">If your trace ran long enough, you'd see more lines like the oneat 00:42:44.817&nbsp;- one line each hour. What's happening is that theserver is making a pass through its cache, freeing any data that hasexpired, to reduce the amount of memory used.</P><PCLASS="para">The master server for this zone is a <SPANCLASS="acronym">BIND</SPAN> 4name server.  If the master were a <SPANCLASS="acronym">BIND</SPAN> 8 nameserver, the slave would be notified when a zone changed rather thanwaiting for the refresh interval to expire.  The slave server's debugoutput would look almost exactly the same, but the trigger to checkthe zone status is a <SPANCLASS="acronym">NOTIFY</SPAN>:</P><BLOCKQUOTECLASS="screen"><PRECLASS="screen">rcvd NOTIFY(movie.edu, IN, SOA) from [192.249.249.3].1059qserial_query(movie.edu)sysquery: send -&gt; [192.249.249.3].53 dfd=5<ACLASS="indexterm"NAME="AUTOID-13251"></A><ACLASS="indexterm"NAME="AUTOID-13252"></A><ACLASS="indexterm"NAME="AUTOID-13253"></A>          nsid=29790 id=0 retry=888048802<ACLASS="indexterm"NAME="AUTOID-13254"></A><ACLASS="indexterm"NAME="AUTOID-13255"></A></PRE></BLOCKQUOTE></DIV></DIV><DIVCLASS="htmlnav"><P></P><HRALIGN="LEFT"WIDTH="515"TITLE="footer"><TABLEWIDTH="515"BORDER="0"CELLSPACING="0"CELLPADDING="0"><TR><TDALIGN="LEFT"VALIGN="TOP"WIDTH="172"><ACLASS="SECT1"HREF="ch12_02.htm"TITLE="12.2 Turning On Debugging"><IMGSRC="../gifs/txtpreva.gif"ALT="Previous: 12.2 Turning On Debugging"BORDER="0"></A></TD><TDALIGN="CENTER"VALIGN="TOP"WIDTH="171"><ACLASS="book"HREF="index.htm"TITLE="DNS &amp; BIND"><IMGSRC="../gifs/txthome.gif"ALT="DNS &amp; BIND"BORDER="0"></A></TD><TDALIGN="RIGHT"VALIGN="TOP"WIDTH="172"><ACLASS="SECT1"HREF="ch12_04.htm"TITLE="12.4 The Resolver Search Algorithm and Negative Caching"><IMGSRC="../gifs/txtnexta.gif"ALT="Next: 12.4 The Resolver Search Algorithm and Negative Caching"BORDER="0"></A></TD></TR><TR><TDALIGN="LEFT"VALIGN="TOP"WIDTH="172">12.2 Turning On Debugging</TD><TDALIGN="CENTER"VALIGN="TOP"WIDTH="171"><ACLASS="index"HREF="index/idx_0.htm"TITLE="Book Index"><IMGSRC="../gifs/index.gif"ALT="Book Index"BORDER="0"></A></TD><TDALIGN="RIGHT"VALIGN="TOP"WIDTH="172">12.4 The Resolver Search Algorithm and Negative Caching</TD></TR></TABLE><HRALIGN="LEFT"WIDTH="515"TITLE="footer"><PCLASS="nav"><FONTSIZE="-1">[ <AHREF="../index.htm"TITLE="The Networking CD Bookshelf">Library Home</A> | <AHREF="index.htm"TITLE="DNS &amp; BIND">DNS &amp; BIND</A> | <AHREF="../tcpip/index.htm"TITLE="TCP/IP Network Administration">TCP/IP</A> | <AHREF="../sendmail/index.htm"TITLE="sendmail">sendmail</A> | <AHREF="../smdref/index.htm"TITLE="sendmail Desktop Reference">sendmail Reference</A> | <AHREF="../firewall/index.htm"TITLE="Building Internet Firewalls">Firewalls</A> | <AHREF="../puis/index.htm"TITLE="Practical UNIX &amp; Internet Security">Practical Security</A> ]</FONT></P></DIV></BODY></HTML>