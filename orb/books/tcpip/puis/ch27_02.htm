<HTML><HEAD><TITLE>[Chapter 27] 27.2 Can You Trust Your Suppliers?</TITLE><METANAME="DC.title"CONTENT="Practical UNIX &amp; Internet Security"><METANAME="DC.creator"CONTENT="Simson Garfinkel &amp; Gene Spafford"><METANAME="DC.publisher"CONTENT="O'Reilly &amp; Associates, Inc."><METANAME="DC.date"CONTENT="1999-02-04T00:20:20Z"><METANAME="DC.type"CONTENT="Text.Monograph"><METANAME="DC.format"CONTENT="text/html"SCHEME="MIME"><METANAME="DC.source"CONTENT="1-56592-148-8"SCHEME="ISBN"><METANAME="DC.language"CONTENT="en-US"><METANAME="generator"CONTENT="Jade 1.1/O'Reilly DocBook 3.0 to HTML 4.0"><LINKREV="made"HREF="mailto:online-books@oreilly.com"TITLE="Online Books Comments"><LINKREL="up"HREF="ch27_01.htm"TITLE="27. Who Do You Trust?"><LINKREL="prev"HREF="ch27_01.htm"TITLE="27.1 Can you Trust Your Computer?"><LINKREL="next"HREF="ch27_03.htm"TITLE="27.3 Can You Trust People?"></HEAD><BODYBGCOLOR="#FFFFFF"TEXT="#000000"><DIVCLASS="htmlnav"><H1><IMGSRC="gifs/smbanner.gif"ALT="Practical UNIX &amp; Internet Security"USEMAP="#srchmap"BORDER="0"></H1><MAPNAME="srchmap"><AREASHAPE="RECT"COORDS="0,0,466,65"HREF="index.htm"ALT="Practical UNIX &amp; Internet Security"><AREASHAPE="RECT"COORDS="467,0,514,18"HREF="../search/psrch.htm"ALT="Search this book"></MAP><TABLEWIDTH="515"BORDER="0"CELLSPACING="0"CELLPADDING="0"><TR><TDALIGN="LEFT"VALIGN="TOP"WIDTH="172"><ACLASS="SECT1"HREF="ch27_01.htm"TITLE="27.1 Can you Trust Your Computer?"><IMGSRC="../gifs/txtpreva.gif"ALT="Previous: 27.1 Can you Trust Your Computer?"BORDER="0"></A></TD><TDALIGN="CENTER"VALIGN="TOP"WIDTH="171"><B><FONTFACE="ARIEL,HELVETICA,HELV,SANSERIF"SIZE="-1">Chapter 27<BR>Who Do You Trust?</FONT></B></TD><TDALIGN="RIGHT"VALIGN="TOP"WIDTH="172"><ACLASS="SECT1"HREF="ch27_03.htm"TITLE="27.3 Can You Trust People?"><IMGSRC="../gifs/txtnexta.gif"ALT="Next: 27.3 Can You Trust People?"BORDER="0"></A></TD></TR></TABLE>&nbsp;<HRALIGN="LEFT"WIDTH="515"TITLE="footer"></DIV><DIVCLASS="SECT1"><H2CLASS="sect1"><ACLASS="title"NAME="PUIS-CHP-27-SECT-2">27.2 Can You Trust Your Suppliers?</A></H2><PCLASS="para">Your computer does something suspicious. You discover thatthe modification dates on your system software have changed. Itappears that an attacker has broken in, or that some kind of virusis spreading. So what do you do? You save your files to backup tapes,format your hard disks, and reinstall your computer's operatingsystem and programs from the original distribution media.</P><PCLASS="para">Is this really the right plan? You can never know. Perhapsyour problems were the result of a break-in. But sometimes, theworst is brought to you by the people who sold you your hardwareand software in the first place.</P><DIVCLASS="sect2"><H3CLASS="sect2"><ACLASS="title"NAME="PUIS-CHP-27-SECT-2.1">27.2.1 Hardware Bugs</A></H3><PCLASS="para"><ACLASS="indexterm"NAME="AUTOID-35790"></A><ACLASS="indexterm"NAME="AUTOID-35793"></A>The factthat Intel Pentium processors had a floating-point problem thatinfrequently resulted in a significant loss of precision when performingsome division operations was revealed to the public in 1994. Notonly had Intel officials known about this, but apparently they haddecided not to tell their customers until after there was significantnegative public reaction.</P><PCLASS="para">Several vendors of disk drives have had problems with theirproducts failing suddenly and catastrophically, sometimes withindays of being placed in use. Other disk drives failed when theywere used with <SPANCLASS="acronym">UNIX</SPAN>, but not with the vendor'sown proprietary operating system. The reason: <SPANCLASS="acronym">UNIX</SPAN>did not run the necessary command to map out bad blocks on the media.Yet, these drives were widely bought for use with the <SPANCLASS="acronym">UNIX</SPAN>operating system.</P><PCLASS="para">Furthermore, there are many cases of effective <ICLASS="filename"><ACLASS="indexterm"NAME="AUTOID-35802"></A>self-destruct sequences</I> in variouskinds of terminals and computers. For example, Digital'soriginal <ACLASS="indexterm"NAME="AUTOID-35804"></A>VT100 terminal hadan escape sequence that switched the terminal from a 60Hz refreshrate to a 50Hz refresh rate, and another escape sequence that switchedit back. By repeatedly sending the two escape sequences to a VT100terminal, a malicious programmer could cause the terminal'sflyback transformer to burn out&nbsp;- sometimes spectacularly!</P><PCLASS="para">A similar sequence of instructions could be used to breakthe monochrome monitor on the original <SPANCLASS="acronym">IBM</SPAN> PCvideo display.</P></DIV><DIVCLASS="sect2"><H3CLASS="sect2"><ACLASS="title"NAME="PUIS-CHP-27-SECT-2.2">27.2.2 Viruses on the Distribution Disk</A></H3><PCLASS="para"><ACLASS="indexterm"NAME="AUTOID-35811"></A><ACLASS="indexterm"NAME="AUTOID-35813"></A>Afew years ago, there was a presumption in the field of computersecurity that manufacturers who distributed computer software tookthe time and due diligence to ensure that their computer programs,if not free of bugs and defects, were at least free of computerviruses and glaring computer security holes. Users were warned notto run shareware and not to download programs from bulletin boardsystems, because such programs were likely to contain viruses orTrojan horses. Indeed, at least one company, which manufactureda shareware virus scanning program, made a small fortune tellingthe world that everybody else's shareware programs werepotentially unsafe.</P><PCLASS="para">Time and experience have taught us otherwise.</P><PCLASS="para">In recent years, a few viruses have been distributed withshareware, but we have also seen many viruses distributed in shrink-wrappedprograms. The viruses come from small companies, and from the makersof major computer systems. Even Microsoft distributed a <SPANCLASS="acronym">CD-ROM</SPAN>with a virus hidden inside a macro for Microsoft Word. The Bureauof the Census distributed a <SPANCLASS="acronym">CD-ROM</SPAN> with a viruson it. One of the problems posed by viruses on distribution disksis that many installation procedures require that the user disableany antiviral software that is running.</P><PCLASS="para">The mass-market software industry has also seen a problemwith <ACLASS="indexterm"NAME="AUTOID-35822"></A><ACLASS="indexterm"NAME="AUTOID-35824"></A><ACLASS="indexterm"NAME="AUTOID-35826"></A><ACLASS="indexterm"NAME="AUTOID-35829"></A>logic bombs and Trojan horses. For example, in1994, Adobe distributed a version of a new Photoshop 3.0 for theMacintosh with a &quot;time bomb&quot; designed to makethe program stop working at some point in the future; the time bombhad inadvertently been left in the program from the beta-testingcycle. Because commercial software is not distributed in sourcecode form, you cannot inspect a program and tell if this kind ofintentional bug is present or not.</P><PCLASS="para">Like shrink-wrapped programs, <ACLASS="indexterm"NAME="AUTOID-35833"></A>sharewareis also a mixed bag. Some shareware sites have system administratorswho are very conscientious, and who go to great pains to scan theirsoftware libraries with viral scanners before making them availablefor download. Other sites have no controls, and allow users to placefiles directly in the download libraries. In the spring of 1995,a program called PKZIP30.EXE made its way around a variety of <SPANCLASS="acronym">FTP</SPAN>sites on the Internet and through America Online. This program appearedto be the 3.0 beta release of <SPANCLASS="acronym">PKZIP</SPAN>, a popular<SPANCLASS="acronym">DOS</SPAN> compression utility. But when the programwas run, it erased the user's hard disk.</P></DIV><DIVCLASS="sect2"><H3CLASS="sect2"><ACLASS="title"NAME="PUIS-CHP-27-SECT-2.3">27.2.3 Buggy Software</A></H3><PCLASS="para"><ACLASS="indexterm"NAME="AUTOID-35841"></A>Consider the following, rathertypical, disclaimer on a piece of distributed software:</P><BLOCKQUOTECLASS="blockquote"><PCLASS="para">NO WARRANTY OF PERFORMANCE. THE PROGRAM AND ITSASSOCIATED DOCUMENTATION ARE LICENSED &quot;AS IS&quot;WITHOUT WARRANTY AS TO THEIR PERFORMANCE, MERCHANTABILITY, OR FITNESSFOR ANY PARTICULAR PURPOSE. THE ENTIRE RISK AS TO THE RESULTS ANDPERFORMANCE OF THE PROGRAM IS ASSUMED BY YOU AND YOUR DISTRIBUTEES.SHOULD THE PROGRAM PROVE DEFECTIVE, YOU AND YOUR DISTRIBUTEES (ANDNOT THE VENDOR) ASSUME THE ENTIRE COST OF ALL NECESSARY SERVICING,REPAIR, OR CORRECTION.</P></BLOCKQUOTE><PCLASS="para">Software sometimes has bugs. You install it on your disk,and under certain circumstances, it damages your files or returnsincorrect results. The examples are legion. You may think that thesoftware is infected with a virus&nbsp;- it is certainly behavingas if it is infected with a virus&nbsp;- but the problem is merelythe result of poor programming.</P><PCLASS="para">If the creators and vendors of the software don'thave confidence in their own software, why should you? If the vendorsdisclaim &quot;...warranty as to [its]performance, merchantability, or fitness for any particular purpose,&quot;then why are you paying them money and using their software as abase for your business?</P><PCLASS="para">Unfortunately, quality is not a priority for most softwarevendors. In most cases, they license the software to you with abroad disclaimer of warranty (similar to the above) so there islittle incentive for them to be sure that every bug has been eradicatedbefore they go to market. The attitude is often one of &quot;We'llfix it in the next release, after the customers have found all thebugs.&quot; Then they introduce new features with new bugs.Yet people wait in line at midnight to be the first to buy softwarethat is full of bugs and may erase their disks when they try toinstall it.</P><PCLASS="para">Other bugs abound. Recall that the first study by ProfessorBarton Miller, cited in <ACLASS="xref"HREF="ch23_01.htm"TITLE="Writing Secure SUID and Network Programs">Chapter 23, <CITECLASS="chapter">Writing Secure SUID and Network Programs</CITE></A>,found that more than one-third of common programs supplied by several<SPANCLASS="acronym">UNIX</SPAN> vendors crashed or hung when they were testedwith a trivial program that generated random input. Five years later,he reran the tests. The results? Although most vendors had improvedto where &quot;only&quot; one-fourth of the programs crashed,one vendor's software exhibited a 46% failurerate! This failure rate was despite wide circulation and publicationof the report, and despite the fact that Miller's teammade the test code available for free to vendors.</P><PCLASS="para">Most frightening, the testing performed by Miller'sgroup is one of the simplest, least-effective forms of testing thatcan be performed (random, black-box testing). Do vendors do anyreasonable testing at all?</P><PCLASS="para">Consider the case of a software engineer from a major PC softwarevendor who came to Purdue to recruit in 1995. During his presentation,students reported that he stated that two of the top 10 reasonsto work for his company were &quot;You don't need tobother with that software engineering stuff&nbsp;- you simplyneed to love to code&quot; and &quot;You'd ratherwrite assembly code than test software.&quot; As you might expect,the company has developed a reputation for quality problems. Whatis surprising is that they continue to be a market leader, yearafter year, and that people continue to buy their software.[3]</P><BLOCKQUOTECLASS="footnote"><PCLASS="para">[3] The same company introduced a product that responded to awrong password being typed three times in a row by prompting theuser with something to the effect of, &quot;You appear to haveset your password to something too difficult to remember. Wouldyou like to set it to something simpler?&quot; Analysis of thisapproach is left as an exercise for the reader.</P></BLOCKQUOTE><PCLASS="para">What's your vendor's policy about testingand good software engineering practices?</P><PCLASS="para">Or, consider the case of someone who implements security featureswithout really understanding the &quot;big picture.&quot;As we noted in &quot;Picking a Random Seed&quot; in <ACLASS="xref"HREF="ch23_01.htm"TITLE="Writing Secure SUID and Network Programs">Chapter 23</A>,a sophisticated encryption algorithm was built into Netscape Navigatorto protect credit card numbers in transit on the network. Unfortunately,the implementation used a weak initialization of the &quot;randomnumber&quot; used to generate a system key. The result? Someonewith an account on a client machine could easily obtain enough informationto crack the key in a matter of seconds, using only a small program.</P></DIV><DIVCLASS="sect2"><H3CLASS="sect2"><ACLASS="title"NAME="PUIS-CHP-27-SECT-2.4">27.2.4 Hacker Challenges</A></H3><PCLASS="para"><ACLASS="indexterm"NAME="AUTOID-35861"></A><ACLASS="indexterm"NAME="AUTOID-35863"></A><ACLASS="indexterm"NAME="AUTOID-35866"></A>Over the past decade,several vendors have issued public challenges stating that theirsystems are secure because they haven't been broken by&quot;hacker challenges.&quot; Usually, these challengesinvolve some vendor putting its system on the Internet and invitingall comers to take a whack in return for some token prize. Then,after a few weeks or months, the vendor shuts down the site, proclaimstheir product invulnerable, and advertises the results as if theywere a badge of honor. But consider the following:</P><ULCLASS="itemizedlist"><LICLASS="listitem"><PCLASS="para">Few such &quot;challenges&quot;are conducted using established testing techniques. They are adhoc, random tests.</P></LI><LICLASS="listitem"><PCLASS="para">That no problems are found does not mean that noproblems exist. The testers might not have exposed them yet. Or,the testers might not have recognized them. (Consider how oftensoftware is released with bugs, even after careful scrutiny.) Furthermore,how do you know that the testers will report what they find? Insome cases, the information may be more valuable to the hackerslater on, after the product has been sold to many customers&nbsp;- becauseat that time, they'll have more profitable targets to pursue.</P></LI><LICLASS="listitem"><PCLASS="para">Simply because the vendor does not report a successfulpenetration does not mean that one did not occur&nbsp;- the vendormay choose not to report it because it would reflect poorly on theproduct. Or, the vendor may not have recognized the penetration.</P></LI><LICLASS="listitem"><PCLASS="para">Challenges give potential miscreants some periodto practice breaking the system without penalty. Challenges alsogive miscreants an excuse if they are caught trying to break intothe system later (e.g., &quot;We thought the contest was stillgoing on.&quot;)</P></LI><LICLASS="listitem"><PCLASS="para">Seldom do the really good experts, on either sideof the fence, participate in such exercises. Thus, anything doneis usually done by amateurs. (The &quot;honor&quot; of havingwon the challenge is not sufficient to lure the good ones into thechallenge. Think about it&nbsp;- good consultants can commandfees of several thousand dollars per day in some cases&nbsp;- whyshould they effectively donate their time and names for free advertising?)</P></LI></UL><PCLASS="para">Furthermore, the whole process sends the wrong messages&nbsp;- thatwe should build things and then try to break them (rather than buildingthem right in the first place), or that there is some prestige orglory in breaking systems. We don't test the strengthsof bridges by driving over them with a variety of cars and trucksto see if they fail, and pronounce them safe if no collapse occursduring the test.</P><PCLASS="para">Some software designers could learn a lot from civil engineers.So might the rest of us: in ancient times, if a house fell or abridge collapsed and injured someone, the engineer who designedit was crushed to death in the rubble as punishment!</P><PCLASS="para">Next time you see an advertiser using a challenge to sella product, you should ask if the challenger is really giving youmore confidence in the product...or convincing you that thevendor doesn't have a clue as to how to really design andtest security.</P><PCLASS="para">If you think that a security challenge builds the right kindof trust, then get in touch with us. We have these magic pendants.No one wearing one has ever had a system broken into, despite challengesto all the computer users who happened to be around when the systemswere developed. Thus, the pendants must be effective at keepingout hackers. We'll be happy to sell some to you. Afterall, we employ the same rigorous testing methodology as your securitysoftware vendors, so our product must be reliable, right?<ACLASS="indexterm"NAME="AUTOID-35884"></A><ACLASS="indexterm"NAME="AUTOID-35886"></A><ACLASS="indexterm"NAME="AUTOID-35889"></A></P></DIV><DIVCLASS="sect2"><H3CLASS="sect2"><ACLASS="title"NAME="PUIS-CHP-27-SECT-2.5">27.2.5 Security Bugs that Never Get Fixed</A></H3><PCLASS="para"><ACLASS="indexterm"NAME="AUTOID-35895"></A>There is also the question of legitimatesoftware distributed by computer manufacturers that contains glaringsecurity holes. More than a year after the release of sendmail Version8, nearly every major <SPANCLASS="acronym">UNIX</SPAN> vendor was still distributingits computers equipped with sendmail Version 5. (Versions 6 and7 were interim releases which were never released.) While Version8 had many improvements over Version 5, it also had many criticalsecurity patches. Was the unwillingness of <SPANCLASS="acronym">UNIX</SPAN>vendors to adopt Version&nbsp;8 negligence&nbsp;- a demonstrationof their laissez-faire attitude towards computer security&nbsp;- ormerely a reflection of pressing market conditions?[4]Are the two really different?</P><BLOCKQUOTECLASS="footnote"><PCLASS="para">[4] Orwas the new, &quot;improved&quot; program simply too hardto configure? At least one vendor told us that it was.</P></BLOCKQUOTE><PCLASS="para">How about the case in which many vendors still release versionsof <SPANCLASS="acronym">TFTP</SPAN> that, by default, allow remote usersto obtain copies of the password file? What about versions of <SPANCLASS="acronym">RPC</SPAN>that allow users to spoof <SPANCLASS="acronym">NFS</SPAN> by using proxycalls through the <SPANCLASS="acronym">RPC</SPAN> system? What about softwarethat includes a writable <ICLASS="filename">utmp</I> file that enablesa user to overwrite arbitrary system files? Each of these casesis a well-known security flaw. In each case, the vendors did notprovide fixes for years&nbsp;- even now, they may not be fixed.</P><PCLASS="para">Many vendors say that computer security is not a high priority,because they are not convinced that spending more money on computersecurity will pay off for them. Computer companies are rightly concernedwith the amount of money that they spend on computer security. Developinga more secure computer is an expensive proposition that not everycustomer may be willing to pay for. The same level of computer securitymay not be necessary for a server on the Internet as for a serverbehind a corporate firewall, or on a disconnected network. Furthermore,increased computer security will not automatically increase sales:firms that want security generally hire staff who are responsiblefor keeping systems secure; users who do not want (or do not understand)security are usually unwilling to pay for it at any price, and frequentlydisable security when it is provided.</P><PCLASS="para">On the other hand, a computer company is far better equippedto safeguard the security of its operating system than is an individualuser. One reason is that a computer company has access to the system'ssource code. A second reason is that most large companies can easilydevote two or three people to assuring the security of their operatingsystem, whereas most businesses are hard-pressed to devote evena single full-time employee to the job of computer security.</P><PCLASS="para">We believe that computer users are beginning to see systemsecurity and software quality as distinguishing features, much inthe way that they see usability, performance, and new functionalityas features. When a person breaks into a computer, over the Internetor otherwise, the act reflects poorly on the maker of the software.We hope that computer companies will soon make software qualityat least as important as new features.</P></DIV><DIVCLASS="sect2"><H3CLASS="sect2"><ACLASS="title"NAME="PUIS-CHP-27-SECT-2.6">27.2.6 Network Providers that Network Too Well</A></H3><PCLASS="para"><ACLASS="indexterm"NAME="AUTOID-35913"></A>Network providerspose special challenges for businesses and individuals. By theirnature, network providers have computers that connect directly toyour computer network, placing the provider (or perhaps a rogueemployee at the providing company) in an ideal position to launchan attack against your installation. For consumers, providers areusually in possession of confidential billing information belongingto the users. Some providers even have the ability to directly makecharges to a user's credit card or to deduct funds froma user's bank account.</P><PCLASS="para">Dan <ACLASS="indexterm"NAME="AUTOID-35916"></A>Geer, a Cambridge-basedcomputer security professional, tells an interesting story aboutan investment brokerage firm that set up a series of direct IP connectionsbetween its clients' computers and the computers at thebrokerage firm. The purpose of the links was to allow the clientsto trade directly on the brokerage firm's computer system.But as the client firms were also competitors, the brokerage houseequipped the link with a variety of sophisticated firewall systems.</P><PCLASS="para">It turns out, says Geer, that although the firm had protecteditself from its clients, it did not invest the time or money toprotect the clients from each other. One of the firm'sclients proceeded to use the direct connection to break into thesystem operated by another client. A significant amount of proprietaryinformation was stolen before the intrusion was discovered.</P><PCLASS="para">In another case, a series of articles appearing in <EMCLASS="emphasis">TheNew York Times</EM> during the first few months of 1995 revealedhow hacker Kevin <ACLASS="indexterm"NAME="AUTOID-35921"></A>Mitnick allegedlybroke into a computer system operated by Netcom Communications.One of the things that Mitnick is alleged to have stolen was a completecopy of Netcom's client database, including the creditcard numbers for more than 30,000 of Netcom's customers.Certainly, Netcom needed the credit card numbers to bill its customersfor service. But why were they placed on a computer system thatcould be reached from the Internet? Why were they not encrypted?</P><PCLASS="para">Think about all those services that are sprouting up on theWorld Wide Web. They claim to use all kinds of super encryptionprotocols to safeguard your credit card number as it is sent acrossthe network. But remember&nbsp;- you can reach their machinesvia the Internet to make the transaction. What kinds of safeguardsdo they have in place at their sites to protect all the card numbersafter they're collected? If you saw an armored car transferringyour bank's receipts to a &quot;vault&quot; housedin a cardboard box on a park bench, would the strength of the armoredcar cause you to trust the safety of the funds?</P></DIV></DIV><DIVCLASS="htmlnav"><P></P><HRALIGN="LEFT"WIDTH="515"TITLE="footer"><TABLEWIDTH="515"BORDER="0"CELLSPACING="0"CELLPADDING="0"><TR><TDALIGN="LEFT"VALIGN="TOP"WIDTH="172"><ACLASS="SECT1"HREF="ch27_01.htm"TITLE="27.1 Can you Trust Your Computer?"><IMGSRC="../gifs/txtpreva.gif"ALT="Previous: 27.1 Can you Trust Your Computer?"BORDER="0"></A></TD><TDALIGN="CENTER"VALIGN="TOP"WIDTH="171"><ACLASS="book"HREF="index.htm"TITLE="Practical UNIX &amp; Internet Security"><IMGSRC="../gifs/txthome.gif"ALT="Practical UNIX &amp; Internet Security"BORDER="0"></A></TD><TDALIGN="RIGHT"VALIGN="TOP"WIDTH="172"><ACLASS="SECT1"HREF="ch27_03.htm"TITLE="27.3 Can You Trust People?"><IMGSRC="../gifs/txtnexta.gif"ALT="Next: 27.3 Can You Trust People?"BORDER="0"></A></TD></TR><TR><TDALIGN="LEFT"VALIGN="TOP"WIDTH="172">27.1 Can you Trust Your Computer?</TD><TDALIGN="CENTER"VALIGN="TOP"WIDTH="171"><ACLASS="index"HREF="index/idx_0.htm"TITLE="Book Index"><IMGSRC="../gifs/index.gif"ALT="Book Index"BORDER="0"></A></TD><TDALIGN="RIGHT"VALIGN="TOP"WIDTH="172">27.3 Can You Trust People?</TD></TR></TABLE><HRALIGN="LEFT"WIDTH="515"TITLE="footer"><PCLASS="nav"><FONTSIZE="-1">[ <AHREF="../index.htm"TITLE="The Networking CD Bookshelf">Library Home</A> | <AHREF="../dnsbind/index.htm"TITLE="DNS &amp; BIND">DNS &amp; BIND</A> | <AHREF="../tcpip/index.htm"TITLE="TCP/IP Network Administration">TCP/IP</A> | <AHREF="../sendmail/index.htm"TITLE="sendmail">sendmail</A> | <AHREF="../smdref/index.htm"TITLE="sendmail Desktop Reference">sendmail Reference</A> | <AHREF="../firewall/index.htm"TITLE="Building Internet Firewalls">Firewalls</A> | <AHREF="index.htm"TITLE="Practical UNIX &amp; Internet Security">Practical Security</A> ]</FONT></P></DIV></BODY></HTML>